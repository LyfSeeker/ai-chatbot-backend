# AI Chatbot Backend - Architecture Documentation

## Table of Contents
1. [System Overview](#system-overview)
2. [High-Level Architecture](#high-level-architecture)
3. [Component Details](#component-details)
4. [Data Flow Diagrams](#data-flow-diagrams)
5. [Database Schema](#database-schema)
6. [Technology Stack](#technology-stack)
7. [Security & Error Handling](#security--error-handling)

---

## System Overview

The AI Chatbot Backend is a production-ready RESTful API that implements **Retrieval Augmented Generation (RAG)** to provide context-aware conversational AI. It combines document upload capabilities, vector similarity search, conversation history management, and multi-LLM support.

### Key Features
- ğŸ“„ **Document Upload**: Process TXT files and generate vector embeddings
- ğŸ’¬ **Conversational AI**: Chat with context from uploaded documents
- ğŸ” **Vector Search**: Semantic similarity search using pgvector
- ğŸ“š **History Management**: Persist and retrieve conversation context
- ğŸ” **Session Isolation**: Separate conversations per session
- ğŸ¤– **Multi-LLM**: Support for OpenAI and Google Gemini

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             CLIENT LAYER                             â”‚
â”‚                     (Postman, Frontend Apps, APIs)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                         â”‚
                   â”‚                         â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  POST /upload          â”‚    â”‚  POST /chat      â”‚
     â”‚  (File Upload API)     â”‚    â”‚  (Chat API)      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                         â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    EXPRESS.JS BACKEND   â”‚
                   â”‚   (Node.js v20+)        â”‚
                   â”‚                         â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                   â”‚  â”‚  ROUTES LAYER   â”‚    â”‚
                   â”‚  â”‚  - upload.js    â”‚    â”‚
                   â”‚  â”‚  - chat.js      â”‚    â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                   â”‚           â”‚             â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                   â”‚  â”‚ SERVICES LAYER  â”‚    â”‚
                   â”‚  â”‚ - embeddings.js â”‚    â”‚
                   â”‚  â”‚ - rag.js        â”‚    â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                   â”‚           â”‚             â”‚
                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                   â”‚  â”‚  DATABASE LAYER â”‚    â”‚
                   â”‚  â”‚  - client.js    â”‚    â”‚
                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚   LangChain    â”‚  â”‚  PostgreSQL â”‚  â”‚ LLM Providerâ”‚
    â”‚   Embeddings   â”‚  â”‚  + pgvector â”‚  â”‚  (Gemini/   â”‚
    â”‚    (OpenAI)    â”‚  â”‚             â”‚  â”‚   OpenAI)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. API Layer (Express.js)

**Location**: `src/index.js`, `src/routes/`

#### Responsibilities:
- HTTP request handling
- Request validation
- Error response formatting
- Route mounting and middleware configuration

#### Endpoints:

| Endpoint | Method | Purpose | Input | Output |
|----------|--------|---------|-------|--------|
| `/` | GET | Health check | None | Status message |
| `/db-test` | GET | Database health | None | Current timestamp |
| `/upload` | POST | Upload document | File + session_id | Success message |
| `/chat` | POST | Chat message | session_id + message | AI response |

---

### 2. Routes Layer

#### Upload Route (`src/routes/upload.js`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         POST /upload Handler                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Receive file via Multer                  â”‚
â”‚  2. Validate session_id and file             â”‚
â”‚  3. Read file content (TXT)                  â”‚
â”‚  4. Call storeEmbeddings()                   â”‚
â”‚  5. Delete temporary file                    â”‚
â”‚  6. Return success response                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**:
- Multer: Multipart form handling
- fs: File system operations
- embeddings.js: Vector generation

---

#### Chat Route (`src/routes/chat.js`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          POST /chat Handler                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Validate session_id and message          â”‚
â”‚  2. INSERT user message to DB                â”‚
â”‚  3. Call generateResponse() for RAG          â”‚
â”‚  4. INSERT assistant reply to DB             â”‚
â”‚  5. Return AI response                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**:
- PostgreSQL pool: Database operations
- rag.js: RAG implementation

---

### 3. Services Layer

#### Embeddings Service (`src/services/embeddings.js`)

**Purpose**: Convert text to vector embeddings for semantic search

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       storeEmbeddings(session_id, text)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Split text into chunks (1000 chars each)   â”‚
â”‚  2. Generate embeddings via OpenAI API         â”‚
â”‚     - Model: text-embedding-ada-002            â”‚
â”‚     - Dimensions: 1536                         â”‚
â”‚  3. Store in documents table (full text)       â”‚
â”‚  4. For each chunk:                            â”‚
â”‚     - Generate embedding vector                â”‚
â”‚     - INSERT into embeddings table             â”‚
â”‚  5. Verify storage with SELECT query           â”‚
â”‚  6. Return success (even if embeddings fail)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features**:
- Graceful degradation on API quota errors
- Chunking strategy for large documents
- Verification logging for debugging

---

#### RAG Service (`src/services/rag.js`)

**Purpose**: Implement Retrieval Augmented Generation for context-aware responses

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    generateResponse(session_id, userMessage)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. RETRIEVE CONVERSATION HISTORY               â”‚
â”‚     SELECT last 10 messages WHERE session_id    â”‚
â”‚                                                  â”‚
â”‚  2. GENERATE QUERY EMBEDDING                    â”‚
â”‚     OpenAI embeddings API for user message      â”‚
â”‚                                                  â”‚
â”‚  3. VECTOR SIMILARITY SEARCH                    â”‚
â”‚     SELECT * FROM embeddings                    â”‚
â”‚     WHERE session_id = ?                        â”‚
â”‚     ORDER BY embedding <-> query_vector         â”‚
â”‚     LIMIT 5                                     â”‚
â”‚                                                  â”‚
â”‚  4. FALLBACK TO DOCUMENTS (if no embeddings)    â”‚
â”‚     SELECT content FROM documents               â”‚
â”‚     WHERE session_id = ?                        â”‚
â”‚                                                  â”‚
â”‚  5. BUILD CONTEXT-AWARE PROMPT                  â”‚
â”‚     - System message                            â”‚
â”‚     - Document context                          â”‚
â”‚     - Conversation history                      â”‚
â”‚     - User query                                â”‚
â”‚                                                  â”‚
â”‚  6. INVOKE LLM (Gemini or OpenAI)               â”‚
â”‚     Based on LLM_PROVIDER env variable          â”‚
â”‚                                                  â”‚
â”‚  7. RETURN AI RESPONSE                          â”‚
â”‚     (or fallback response if LLM fails)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features**:
- pgvector `<->` operator for cosine similarity
- Multi-LLM support (configurable provider)
- History-aware prompting
- Error resilience with fallback responses

---

### 4. Database Layer

**Location**: `src/db/client.js`

**Purpose**: Manage PostgreSQL connection pooling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PostgreSQL Connection Pool   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Reuses connections             â”‚
â”‚  - Handles concurrent queries     â”‚
â”‚  - Auto-reconnection              â”‚
â”‚  - Connection string from env     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Diagrams

### Upload Flow (Document Processing)

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  User   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 1. Upload TXT file + session_id
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Multer   â”‚  Saves to uploads/
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 2. File path
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Upload Routeâ”‚  fs.readFileSync()
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 3. Text content
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Embeddings Svc   â”‚  Split into chunks
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 4. For each chunk
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OpenAI API      â”‚  Generate vector (1536-d)
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 5. Embedding vector
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL      â”‚  INSERT INTO embeddings
    â”‚  (pgvector)      â”‚  INSERT INTO documents
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Chat Flow (RAG Pipeline)

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  User   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 1. Send message + session_id
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Chat Route  â”‚  Save user message
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 2. Trigger RAG
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RAG Serviceâ”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                     â”‚
         â”‚ 3a. Get history                     â”‚ 3b. Get context
         â–¼                                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQL  â”‚                      â”‚  Generate    â”‚
    â”‚ messages    â”‚                      â”‚  query       â”‚
    â”‚ table       â”‚                      â”‚  embedding   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                       â”‚
         â”‚                                       â”‚ 4. Vector search
         â”‚                                       â–¼
         â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                              â”‚  PostgreSQL      â”‚
         â”‚                              â”‚  embeddings      â”‚
         â”‚                              â”‚  (similarity)    â”‚
         â”‚                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ 5. Build prompt (context + history + query)
                        â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  LLM API    â”‚  Gemini or OpenAI
                   â”‚  (Gemini/   â”‚
                   â”‚   OpenAI)   â”‚
                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ 6. AI response
                        â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Save reply  â”‚  INSERT INTO messages
                   â”‚ to DB       â”‚
                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ 7. Return response
                        â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  User   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Database Schema

### Entity Relationship Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    sessions      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (TEXT) PK     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ created_at       â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                               â”‚
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    messages      â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚ id (SERIAL) PK   â”‚           â”‚
â”‚ session_id (FK)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ role (TEXT)      â”‚           â”‚
â”‚ content (TEXT)   â”‚           â”‚
â”‚ created_at       â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   documents      â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚ id (SERIAL) PK   â”‚           â”‚
â”‚ session_id (FK)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ content (TEXT)   â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   embeddings     â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚ id (SERIAL) PK   â”‚           â”‚
â”‚ session_id (FK)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ embedding VECTOR â”‚  â† 1536 dimensions
â”‚ content (TEXT)   â”‚  â† Chunk text
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Table Details

#### `sessions`
- **Purpose**: Track active chat sessions
- **Primary Key**: `id` (user-defined session identifier)
- **Indexes**: Primary key index

#### `messages`
- **Purpose**: Store conversation history
- **Fields**:
  - `role`: "user" or "assistant"
  - `content`: Message text
- **Indexes**: Consider `idx_messages_session` for performance

#### `documents`
- **Purpose**: Full text storage for uploaded files
- **Usage**: Fallback when embeddings are unavailable
- **Indexes**: Consider `idx_documents_session`

#### `embeddings`
- **Purpose**: Vector embeddings for semantic search
- **Fields**:
  - `embedding`: VECTOR(1536) - pgvector type
  - `content`: Original text chunk
- **Indexes**: 
  - Consider `idx_embeddings_session`
  - pgvector uses HNSW or IVFFlat for vector similarity

---

## Technology Stack

### Backend Framework
```
Express.js v5.2.1
â”œâ”€â”€ CORS middleware (cross-origin requests)
â”œâ”€â”€ JSON body parser
â””â”€â”€ URL-encoded parser
```

### Database
```
PostgreSQL 16
â””â”€â”€ pgvector extension
    â”œâ”€â”€ Vector data type
    â””â”€â”€ Similarity operators (<->, <#>, <=>)
```

### LLM Integration
```
LangChain Framework
â”œâ”€â”€ @langchain/openai
â”‚   â”œâ”€â”€ OpenAIEmbeddings (text-embedding-ada-002)
â”‚   â””â”€â”€ ChatOpenAI (gpt-3.5-turbo)
â””â”€â”€ @langchain/google-genai
    â””â”€â”€ ChatGoogleGenerativeAI (gemini-pro)
```

### File Handling
```
Multer v1.4.5-lts.1
â””â”€â”€ Multipart form-data parsing
```

### Containerization
```
Docker
â”œâ”€â”€ PostgreSQL container (pgvector/pgvector:pg16)
â””â”€â”€ Node.js container (node:20-alpine)
```

---

## Security & Error Handling

### Security Measures

1. **Environment Variables**: API keys stored in `.env` (not committed to git)
2. **Input Validation**: Required fields checked on all endpoints
3. **Session Isolation**: All queries filter by `session_id`
4. **File Cleanup**: Temporary uploads deleted after processing
5. **SQL Parameterization**: Prepared statements prevent SQL injection

### Error Handling Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Error Handling Layers           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Route-level try-catch               â”‚
â”‚     â†’ Returns 500 with error message    â”‚
â”‚                                          â”‚
â”‚  2. Service-level graceful degradation  â”‚
â”‚     â†’ Embeddings: Falls back to docs    â”‚
â”‚     â†’ LLM: Returns context-based reply  â”‚
â”‚                                          â”‚
â”‚  3. Database error logging              â”‚
â”‚     â†’ Console.error with context        â”‚
â”‚                                          â”‚
â”‚  4. API quota handling                  â”‚
â”‚     â†’ Continues without embeddings      â”‚
â”‚     â†’ Uses document table fallback      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Graceful Degradation Examples

| Failure Scenario | System Behavior |
|------------------|-----------------|
| OpenAI API quota exceeded | Stores document without embeddings, RAG uses document table |
| Vector search returns empty | Falls back to SELECT from documents table |
| LLM API unavailable | Returns contextual message: "Based on your uploaded documents..." |
| Database connection lost | Returns 500 error with retry suggestion |

---

## Performance Considerations

### Optimization Strategies

1. **Connection Pooling**: PostgreSQL pool reuses connections
2. **Vector Indexing**: pgvector HNSW index for fast similarity search
3. **Chunk Size**: 1000 characters balances context vs. performance
4. **History Limit**: Last 10 messages prevent token overflow
5. **Result Limiting**: Top 5 similar chunks for RAG context

### Scalability

- **Horizontal Scaling**: Stateless design allows multiple instances
- **Database Scaling**: PostgreSQL read replicas for heavy query loads
- **Caching**: Future: Redis for conversation history
- **Async Processing**: File uploads could use job queues for large files

---

## Development Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Development Environment            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Clone repository                       â”‚
â”‚  2. npm install                            â”‚
â”‚  3. docker-compose up postgres -d          â”‚
â”‚  4. Set up .env with API keys              â”‚
â”‚  5. Run database migrations (SQL)          â”‚
â”‚  6. npm run dev (nodemon for hot reload)   â”‚
â”‚  7. Test with Postman                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Testing Approach

- **Manual Testing**: Postman collections
- **Database Verification**: Direct psql queries
- **Log Monitoring**: Console logs with emoji indicators ğŸš€ğŸ“Šâœ…
- **Error Simulation**: Test with invalid API keys, missing fields

---

## Deployment Architecture

### Docker Compose Setup

```
docker-compose.yml
â”œâ”€â”€ postgres (service)
â”‚   â”œâ”€â”€ Image: pgvector/pgvector:pg16
â”‚   â”œâ”€â”€ Port: 5432
â”‚   â”œâ”€â”€ Volume: postgres_data (persistence)
â”‚   â””â”€â”€ Healthcheck: pg_isready
â”‚
â””â”€â”€ backend (service)
    â”œâ”€â”€ Build: Dockerfile
    â”œâ”€â”€ Port: 3000
    â”œâ”€â”€ Depends on: postgres (healthy)
    â””â”€â”€ Environment: API keys, DATABASE_URL
```

### Single-Command Deployment

```bash
docker-compose up -d
```

This starts:
1. PostgreSQL with pgvector
2. Backend Node.js application
3. Automatic health checks and dependencies
4. Persistent data storage

---

## Future Enhancements

1. **PDF Support**: Add pdf-parse for document variety
2. **Authentication**: JWT-based session authentication
3. **Rate Limiting**: Prevent API abuse
4. **Caching**: Redis for conversation history
5. **WebSockets**: Real-time streaming responses
6. **Admin Dashboard**: Session management UI
7. **Analytics**: Track usage metrics and costs
8. **Multi-file Upload**: Batch document processing
9. **File Type Detection**: Automatic format handling
10. **Vector Indexing**: IVFFlat/HNSW tuning for scale

---

**Last Updated**: 2024
**Version**: 1.0.0
**Author**: LyfSeeker
